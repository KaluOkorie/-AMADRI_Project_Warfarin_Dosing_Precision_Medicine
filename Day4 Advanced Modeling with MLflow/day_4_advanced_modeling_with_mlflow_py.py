# -*- coding: utf-8 -*-
"""Day 4: Advanced Modeling with MLflow.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UcX6Hu4oDR-1nO7c-qrk5duMeONQrBah

# Day 4: Advanced Warfarin Modeling with MLflow
"""

# ============================================================================
# SECTION 1: IMPORTS AND SETUP
# ============================================================================
!pip install mlflow
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import GridSearchCV
import mlflow
import mlflow.keras
import mlflow.xgboost
import joblib
import warnings
warnings.filterwarnings('ignore')

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# ============================================================================
# SECTION 2: GENETIC ENCODING FUNCTIONS (From Day 3)
# ============================================================================

def encode_cyp2c9_function(genotype):
    """Convert CYP2C9 genotype to activity score"""
    activity_map = {
        '*1/*1': 2.0,
        '*1/*2': 1.5,
        '*1/*3': 1.0,
        '*2/*2': 1.0,
        '*2/*3': 0.5,
        '*3/*3': 0.0
    }
    phenotype_map = {
        '*1/*1': 'Normal',
        '*1/*2': 'Intermediate',
        '*1/*3': 'Intermediate',
        '*2/*2': 'Poor',
        '*2/*3': 'Poor',
        '*3/*3': 'Poor'
    }
    activity = activity_map.get(genotype, 1.5)
    phenotype = phenotype_map.get(genotype, 'Intermediate')
    return phenotype, activity

def encode_vkorc1_function(genotype):
    """Convert VKORC1 genotype to sensitivity score"""
    sensitivity_map = {
        'G/G': 0.0,
        'A/G': 1.0,
        'A/A': 2.0
    }
    phenotype_map = {
        'G/G': 'Normal',
        'A/G': 'Intermediate',
        'A/A': 'Sensitive'
    }
    sensitivity = sensitivity_map.get(genotype, 1.0)
    phenotype = phenotype_map.get(genotype, 'Intermediate')
    return phenotype, sensitivity

def encode_cyp4f2_function(genotype):
    """Convert CYP4F2 genotype to score"""
    score_map = {
        'C/C': 0.0,
        'C/T': 1.0,
        'T/T': 2.0
    }
    genotype_type = {
        'C/C': 'Normal',
        'C/T': 'Heterozygous',
        'T/T': 'Variant'
    }
    score = score_map.get(genotype, 0.0)
    genotype_desc = genotype_type.get(genotype, 'Normal')
    return genotype_desc, score

# ============================================================================
# SECTION 3: DATA LOADER (Direct from Day 2 outputs)
# ============================================================================

class DataLoader:
    """Loads raw data from Day 2 and applies feature engineering"""

    def __init__(self):
        # Day 2 output files
        self.X_train_file = 'X_train.csv'
        self.X_val_file = 'X_val.csv'
        self.X_test_file = 'X_test.csv'
        self.y_train_file = 'y_train.csv'
        self.y_val_file = 'y_val.csv'
        self.y_test_file = 'y_test.csv'

    def load_raw_data(self):
        """Load raw data from Day 2"""
        X_train = pd.read_csv(self.X_train_file)
        X_val = pd.read_csv(self.X_val_file)
        X_test = pd.read_csv(self.X_test_file)

        y_train = pd.read_csv(self.y_train_file).squeeze()
        y_val = pd.read_csv(self.y_val_file).squeeze()
        y_test = pd.read_csv(self.y_test_file).squeeze()

        print("Raw data loaded:")
        print(f"  X_train: {X_train.shape}")
        print(f"  X_val: {X_val.shape}")
        print(f"  X_test: {X_test.shape}")
        print(f"  y_train: {y_train.shape}")

        return X_train, X_val, X_test, y_train, y_val, y_test

    def engineer_features(self, df):
        """Apply feature engineering identical to Day 3"""
        df = df.copy()

        # Genetic encoding
        df[['CYP2C9_Phenotype', 'CYP2C9_Activity']] = df['CYP2C9'].apply(
            lambda x: pd.Series(encode_cyp2c9_function(x))
        )
        df[['VKORC1_Phenotype', 'VKORC1_Sensitivity']] = df['VKORC1'].apply(
            lambda x: pd.Series(encode_vkorc1_function(x))
        )
        df[['CYP4F2_Genotype', 'CYP4F2_Score']] = df['CYP4F2'].apply(
            lambda x: pd.Series(encode_cyp4f2_function(x))
        )

        # Combined genetic burden
        df['Genetic_Burden'] = (df['CYP2C9_Activity'] + df['VKORC1_Sensitivity']) / 2

        # Clinical calculations
        if 'Height_cm' in df.columns and 'Weight_kg' in df.columns:
            df['BSA'] = 0.007184 * (df['Height_cm'] ** 0.725) * (df['Weight_kg'] ** 0.425)

        if 'Age' in df.columns and 'Weight_kg' in df.columns and 'Sex' in df.columns:
            sex_factor = np.where(df['Sex'] == 'F', 0.85, 1.0)
            df['eGFR'] = ((140 - df['Age']) * df['Weight_kg'] * sex_factor) / (72 * 1.2)
            df['Renal_Impairment'] = (df['eGFR'] < 60).astype(int)

        if 'Age' in df.columns:
            df['Elderly'] = (df['Age'] >= 75).astype(int)

        if 'Height_cm' in df.columns and 'Weight_kg' in df.columns:
            df['BMI'] = df['Weight_kg'] / ((df['Height_cm'] / 100) ** 2)
            df['Obese'] = (df['BMI'] > 30).astype(int)

        if 'Alcohol_Intake' in df.columns:
            df['Alcohol_Intake'] = df['Alcohol_Intake'].fillna('Unknown')

        return df

# ============================================================================
# SECTION 4: DATA PREPROCESSOR
# ============================================================================

class DataPreprocessor:
    """Preprocesses data for modeling"""

    def __init__(self):
        from sklearn.preprocessing import StandardScaler, OneHotEncoder
        from sklearn.compose import ColumnTransformer

        # Define feature types (same as Day 3)
        self.numerical_features = [
            'Age', 'Weight_kg', 'Height_cm', 'CYP2C9_Activity',
            'VKORC1_Sensitivity', 'CYP4F2_Score', 'Genetic_Burden'
        ]

        self.categorical_features = [
            'Sex', 'Ethnicity', 'Alcohol_Intake', 'Smoking_Status',
            'Diet_VitK_Intake'
        ]

        # Create preprocessing pipeline
        self.preprocessor = ColumnTransformer([
            ('num', StandardScaler(), self.numerical_features),
            ('cat', OneHotEncoder(drop='first', sparse_output=False), self.categorical_features)
        ])

    def fit_transform(self, X_train, X_val, X_test):
        """Fit preprocessor and transform all datasets"""
        # Filter to existing features
        num_features = [f for f in self.numerical_features if f in X_train.columns]
        cat_features = [f for f in self.categorical_features if f in X_train.columns]

        print(f"  Numerical features: {len(num_features)}")
        print(f"  Categorical features: {len(cat_features)}")

        # Update preprocessor with actual features
        self.preprocessor = ColumnTransformer([
            ('num', StandardScaler(), num_features),
            ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_features)
        ])

        # Fit and transform
        X_train_processed = self.preprocessor.fit_transform(X_train)
        X_val_processed = self.preprocessor.transform(X_val)
        X_test_processed = self.preprocessor.transform(X_test)

        # Get feature names
        num_feature_names = num_features
        cat_encoder = self.preprocessor.named_transformers_['cat']
        cat_feature_names = list(cat_encoder.get_feature_names_out(cat_features))
        self.feature_names = num_feature_names + cat_feature_names

        # Convert to numpy arrays for ML
        X_train_np = X_train_processed
        X_val_np = X_val_processed
        X_test_np = X_test_processed

        print(f"  Processed feature dimensions: {X_train_np.shape[1]}")

        return X_train_np, X_val_np, X_test_np

# ============================================================================
# SECTION 5: XGBOOST TRAINER
# ============================================================================

class XGBoostTrainer:
    """Trains and tunes XGBoost model"""

    def __init__(self):
        self.model = None
        self.best_params = None

    def train(self, X_train, y_train, X_val, y_val):
        """Train XGBoost with hyperparameter tuning"""
        print("\nTraining XGBoost...")

        # Parameter grid for hyperparameter tuning
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [3, 4, 5],
            'learning_rate': [0.05, 0.1],
            'subsample': [0.8, 0.9],
            'colsample_bytree': [0.8, 0.9]
        }

        # Grid search for best parameters
        xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)
        grid_search = GridSearchCV(
            estimator=xgb_model,
            param_grid=param_grid,
            cv=3,
            scoring='neg_mean_squared_error',
            verbose=0
        )

        grid_search.fit(X_train, y_train)

        # Get best model
        self.model = grid_search.best_estimator_
        self.best_params = grid_search.best_params_

        # Evaluate on validation set
        y_val_pred = self.model.predict(X_val)
        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))

        print(f"  Best parameters: {self.best_params}")
        print(f"  Validation RMSE: {val_rmse:.4f}")

        return self.model

    def evaluate(self, X_test, y_test):
        """Evaluate model on test set"""
        y_pred = self.model.predict(X_test)

        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        return {
            'predictions': y_pred,
            'rmse': rmse,
            'mae': mae,
            'r2': r2
        }

# ============================================================================
# SECTION 6: NEURAL NETWORK TRAINER
# ============================================================================

class NeuralNetworkTrainer:
    """Trains neural network model"""

    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.model = None

    def build_model(self):
        """Build neural network architecture"""
        model = keras.Sequential([
            layers.Dense(64, activation='relu', input_shape=self.input_shape),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            layers.Dense(32, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),

            layers.Dense(16, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.1),

            layers.Dense(1)
        ])

        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )

        self.model = model
        return model

    def train(self, X_train, y_train, X_val, y_val):
        """Train neural network"""
        print("\nTraining neural network...")

        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            min_delta=0.001
        )

        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=100,
            batch_size=32,
            callbacks=[early_stopping],
            verbose=0
        )

        # Evaluate on validation set
        y_val_pred = self.model.predict(X_val).flatten()
        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))

        print(f"  Training epochs: {len(history.history['loss'])}")
        print(f"  Validation RMSE: {val_rmse:.4f}")

        return self.model

    def evaluate(self, X_test, y_test):
        """Evaluate model on test set"""
        y_pred = self.model.predict(X_test).flatten()

        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        return {
            'predictions': y_pred,
            'rmse': rmse,
            'mae': mae,
            'r2': r2
        }

# ============================================================================
# SECTION 7: CLINICAL EVALUATOR
# ============================================================================

class ClinicalEvaluator:
    """Performs clinical evaluation of models"""

    def evaluate_model(self, y_true, y_pred, model_name):
        """Comprehensive clinical evaluation"""
        # Basic metrics
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        # Clinical accuracy metrics
        clinical_accuracy = {
            'High Precision (±0.5mg)': (np.abs(y_true - y_pred) <= 0.5).mean() * 100,
            'Clinical Standard (±1.0mg)': (np.abs(y_true - y_pred) <= 1.0).mean() * 100,
            'Safety Threshold (±2.0mg)': (np.abs(y_true - y_pred) <= 2.0).mean() * 100
        }

        # Safety metrics
        safety_metrics = {
            'Over-prediction (>1mg)': (y_pred > y_true + 1.0).mean() * 100,
            'Under-prediction (>1mg)': (y_pred < y_true - 1.0).mean() * 100
        }

        return {
            'model_name': model_name,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'clinical_accuracy': clinical_accuracy,
            'safety_metrics': safety_metrics
        }

# ============================================================================
# SECTION 7: CLINICAL EVALUATOR
# ============================================================================

class ClinicalEvaluator:
    """Performs clinical evaluation of models"""

    def evaluate_model(self, y_true, y_pred, model_name):
        """Comprehensive clinical evaluation"""
        # Basic metrics
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        # Clinical accuracy metrics
        clinical_accuracy = {
            'High Precision (±0.5mg)': (np.abs(y_true - y_pred) <= 0.5).mean() * 100,
            'Clinical Standard (±1.0mg)': (np.abs(y_true - y_pred) <= 1.0).mean() * 100,
            'Safety Threshold (±2.0mg)': (np.abs(y_true - y_pred) <= 2.0).mean() * 100
        }

        # Safety metrics
        safety_metrics = {
            'Over-prediction (>1mg)': (y_pred > y_true + 1.0).mean() * 100,
            'Under-prediction (>1mg)': (y_pred < y_true - 1.0).mean() * 100
        }

        return {
            'model_name': model_name,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'clinical_accuracy': clinical_accuracy,
            'safety_metrics': safety_metrics
        }

# ============================================================================
# SECTION 8: MLFLOW TRACKER
# ============================================================================

class MLflowTracker:
    """Manages MLflow experiment tracking"""

    def __init__(self):
        mlflow.set_tracking_uri("file:./mlruns")
        mlflow.set_experiment("Warfarin_Dosing_Day4")

    def log_experiment(self, model, model_name, results, params=None, is_nn=False):
        """Log experiment to MLflow"""
        with mlflow.start_run(run_name=model_name):
            # Log parameters
            if params:
                mlflow.log_params(params)

            # Log metrics
            mlflow.log_metrics({
                'test_rmse': results['rmse'],
                'test_mae': results['mae'],
                'test_r2': results['r2'],
                'clinical_accuracy_1mg': results['clinical_accuracy']['Clinical Standard (±1.0mg)']
            })

            # Log model
            if is_nn:
                mlflow.keras.log_model(model, "model")
            else:
                mlflow.xgboost.log_model(model, "model")

# ============================================================================
# SECTION 9: MAIN PIPELINE
# ============================================================================

class Day4Pipeline:
    """Orchestrates Day 4 advanced modeling pipeline"""

    def run(self):
        """Execute complete Day 4 pipeline"""
        print("=" * 70)
        print("DAY 4: ADVANCED MODELING & EVALUATION")
        print("=" * 70)

        # Step 1: Load and prepare data
        print("\nSTEP 1: LOADING AND PREPARING DATA")
        print("-" * 40)

        data_loader = DataLoader()
        X_train_raw, X_val_raw, X_test_raw, y_train, y_val, y_test = data_loader.load_raw_data()

        # Apply feature engineering
        print("Applying feature engineering...")
        X_train_fe = data_loader.engineer_features(X_train_raw)
        X_val_fe = data_loader.engineer_features(X_val_raw)
        X_test_fe = data_loader.engineer_features(X_test_raw)

        # Preprocess data
        print("Preprocessing data...")
        preprocessor = DataPreprocessor()
        X_train, X_val, X_test = preprocessor.fit_transform(X_train_fe, X_val_fe, X_test_fe)

        # Step 2: Train XGBoost
        print("\nSTEP 2: TRAINING XGBOOST")
        print("-" * 40)

        xgb_trainer = XGBoostTrainer()
        xgb_model = xgb_trainer.train(X_train, y_train, X_val, y_val)
        xgb_eval = xgb_trainer.evaluate(X_test, y_test)

        # Step 3: Train Neural Network
        print("\nSTEP 3: TRAINING NEURAL NETWORK")
        print("-" * 40)

        nn_trainer = NeuralNetworkTrainer(input_shape=(X_train.shape[1],))
        nn_model = nn_trainer.build_model()
        nn_model = nn_trainer.train(X_train, y_train, X_val, y_val)
        nn_eval = nn_trainer.evaluate(X_test, y_test)

        # Step 4: Clinical evaluation
        print("\nSTEP 4: CLINICAL EVALUATION")
        print("-" * 40)

        clinical_evaluator = ClinicalEvaluator()
        xgb_results = clinical_evaluator.evaluate_model(y_test, xgb_eval['predictions'], 'XGBoost')
        nn_results = clinical_evaluator.evaluate_model(y_test, nn_eval['predictions'], 'Neural Network')

        # Display results
        print("\nModel Performance Comparison:")
        print("=" * 50)
        print(f"{'Metric':<25} {'XGBoost':<15} {'Neural Network':<15}")
        print("-" * 50)
        print(f"{'RMSE':<25} {xgb_results['rmse']:<15.4f} {nn_results['rmse']:<15.4f}")
        print(f"{'MAE':<25} {xgb_results['mae']:<15.4f} {nn_results['mae']:<15.4f}")
        print(f"{'R2':<25} {xgb_results['r2']:<15.4f} {nn_results['r2']:<15.4f}")
        print(f"{'Clinical Accuracy (±1mg)':<25} {xgb_results['clinical_accuracy']['Clinical Standard (±1.0mg)']:<15.1f}% {nn_results['clinical_accuracy']['Clinical Standard (±1.0mg)']:<15.1f}%")

        # Step 5: MLflow tracking
        print("\nSTEP 5: MLFLOW TRACKING")
        print("-" * 40)

        mlflow_tracker = MLflowTracker()
        mlflow_tracker.log_experiment(xgb_model, "XGBoost", xgb_results, xgb_trainer.best_params, is_nn=False)
        mlflow_tracker.log_experiment(nn_model, "Neural_Network", nn_results, is_nn=True)

        print("MLflow tracking complete")
        print("To view results: mlflow ui --backend-store-uri file:./mlruns")

        # Step 6: Model selection and saving
        print("\nSTEP 6: MODEL SELECTION AND SAVING")
        print("-" * 40)

        # Select best model based on RMSE
        if xgb_results['rmse'] <= nn_results['rmse']:
            selected_model = xgb_model
            selected_name = "XGBoost"
            filename = "final_warfarin_model_xgboost.pkl"
            joblib.dump(selected_model, filename)
        else:
            selected_model = nn_model
            selected_name = "Neural Network"
            filename = "final_warfarin_model_nn.h5"
            selected_model.save(filename)

        print(f"Selected model: {selected_name}")
        print(f"Saved as: {filename}")
        print(f"Test RMSE: {min(xgb_results['rmse'], nn_results['rmse']):.4f}")

        print("\n" + "=" * 70)
        print("=" * 70)

# ============================================================================
# SECTION 10: EXECUTION
# ============================================================================

if __name__ == "__main__":
    # Run the pipeline
    pipeline = Day4Pipeline()
    pipeline.run()

    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print("1. Data loaded from Day 2 outputs")
    print("2. Feature engineering applied (identical to Day 3)")
    print("3. XGBoost and Neural Network models trained")
    print("4. Models evaluated with clinical metrics")
    print("5. Experiments tracked with MLflow")
    print("6. Best model selected and saved")
    print("=" * 70)